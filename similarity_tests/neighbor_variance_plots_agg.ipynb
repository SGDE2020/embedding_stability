{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import variation\n",
    "from time import time\n",
    "from neighbor_variance import neighbor_variance, get_file_list\n",
    "from collections import defaultdict\n",
    "\n",
    "from scale_to_latex import get_columnwidth, get_textwidth, get_figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where graphs are stored\n",
    "d = \"../train/data/\"\n",
    "graphdirs = [\n",
    "    f\"{d}Cora/\",\n",
    "    f\"{d}Facebook/\",\n",
    "    f\"{d}Protein/\",\n",
    "    f\"{d}BlogCatalog/\",\n",
    "    f\"{d}Wikipedia/\"\n",
    "]\n",
    "\n",
    "# Folder where embeddings are stored\n",
    "r = \"../train/results/\"\n",
    "resultdirs = [\n",
    "    r + \"Cora/\",\n",
    "    r + \"Facebook/\",\n",
    "    r + \"Protein/\",\n",
    "    r + \"BlogCatalog/\",\n",
    "    r + \"Wikipedia/\"\n",
    "]\n",
    "\n",
    "algorithms = [\n",
    "    \"graphsage\",\n",
    "#    \"hope\",\n",
    "    \"line\",\n",
    "    \"node2vec\",\n",
    "    \"sdne\"\n",
    "]\n",
    "\n",
    "datasets = [\n",
    "    \"cora\",\n",
    "    \"facebook\",\n",
    "    \"protein\",\n",
    "    \"blog\",\n",
    "    \"wikipedia\"\n",
    "]\n",
    "\n",
    "replace_dict = {\"line\":\"LINE\", \"hope\":\"HOPE\", \"sdne\":\"SDNE\", \"graphsage\":\"GraphSAGE\", \"node2vec\":\"node2vec\",\n",
    "                \"facebook\":\"Facebook\", \"protein\":\"Protein\", \"blog\":\"BlogCatalog\", \"wikipedia\": \"Wikipedia\", \"cora\": \"Cora\"}\n",
    "color_dict = {\"LINE\":\"#E30066\", \"HOPE\":\"#612158\", \"SDNE\":\"#F6A800\", \"GraphSAGE\":\"#00549F\", \"node2vec\":\"#57AB27\"}\n",
    "seed = 87235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Run the neighbor_variance experiment for all specified datasets and algorithms. \n",
    "    For every dataset the nodes are only sampled once and saved as a file.\n",
    "\"\"\"\n",
    "start_time = time()\n",
    "df = pd.DataFrame()\n",
    "agg_list = []\n",
    "k = 1600\n",
    "min_nodes = 10000 # larger than sample size\n",
    "for i in range(len(datasets)):\n",
    "    tmp_df = pd.DataFrame()\n",
    "    nodes = None\n",
    "    for algo in algorithms:\n",
    "        embedding_list = get_file_list([algo, datasets[i]], resultdirs[i])\n",
    "        aggregated_results, raw_results, nodes = neighbor_variance(graphdirs[i], k, resultdirs[i],\n",
    "                                                                   embedding_list, datasets[i], nodes_dict=nodes, seed=seed)\n",
    "        # preaggregate into variances\n",
    "        variance_dict = defaultdict(list)\n",
    "        for node in raw_results[\"node\"].unique():\n",
    "            for j in raw_results[\"neighbor_type\"].unique():\n",
    "                variance_dict[\"node\"].append(node)\n",
    "                variance_dict[\"neighbor_type\"].append(j)\n",
    "                variance_dict[\"algorithm\"].append(algo)\n",
    "                variance_dict[\"dataset\"].append(datasets[i])\n",
    "                sel = raw_results.loc[(raw_results.node == node) & (raw_results.neighbor_type == j), \"similarity\"]\n",
    "                variance_dict[\"variance\"].append(np.var(sel))\n",
    "                variance_dict[\"mean\"].append(np.mean(sel))\n",
    "                variance_dict[\"mean_abs_dev_deg\"].append(sel.transform(lambda x: np.degrees(np.arccos(x))).mad())\n",
    "        tmp_df = tmp_df.append(pd.DataFrame(variance_dict))\n",
    "        agg_list.append([algo, i, aggregated_results])\n",
    "\n",
    "    \n",
    "    with open(f\"./nb_var_nodes/{datasets[i]}_nodes\", \"wb\") as node_file:\n",
    "        pickle.dump(nodes, node_file)\n",
    "    # only keep those nodes that have 1-nb, 2-nb, distant(-nb)\n",
    "    # the length will be a multiple of 90\n",
    "    notnan_nodes = [node for node in nodes.keys() if None not in nodes[node]]\n",
    "    tmp_df = tmp_df.loc[tmp_df.node.isin(notnan_nodes)]\n",
    "    \n",
    "    # combine dataframes\n",
    "    df = df.append(tmp_df)\n",
    "    min_nodes = min(min_nodes, len(tmp_df.node.unique()))\n",
    "print(f\"Computing the data frame took {time()-start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\"\"\" \n",
    "    Make sample size consistent\n",
    "\"\"\"\n",
    "save_df = df.copy()\n",
    "udf = pd.DataFrame()\n",
    "for i, dataset in enumerate(datasets):\n",
    "    tmp = df[df.dataset == dataset]\n",
    "    sampled_nodes = tmp.node.unique()\n",
    "    np.random.shuffle(sampled_nodes)\n",
    "    kept_nodes = sampled_nodes[:min_nodes]\n",
    "    udf = udf.append(tmp[tmp.node.isin(kept_nodes)].copy())\n",
    "    print(dataset, len(udf[udf.dataset == dataset].node.unique()))\n",
    "print(min_nodes)\n",
    "df = udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(to_replace=replace_dict)\n",
    "df.rename(columns={\"algorithm\": \"Algorithm\"}, inplace=True)\n",
    "#df[\"Algorithm\"] = pd.Categorical(df[\"Algorithm\"], [\"HOPE\", \"LINE\", \"node2vec\", \"SDNE\", \"GraphSAGE\"])\n",
    "df[\"Algorithm\"] = pd.Categorical(df[\"Algorithm\"], [\"LINE\", \"node2vec\", \"SDNE\", \"GraphSAGE\"])\n",
    "df[\"neighbor_type\"] = df[\"neighbor_type\"].replace(to_replace={0:\"1-Hop Neighbor\", 1:\"2-Hop Neighbor\", 2:\"Distant Node\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cora and blog\n",
    "angle = 40\n",
    "columnwidth = get_columnwidth()\n",
    "textwidth = get_textwidth()\n",
    "light_gray = \".8\"\n",
    "dark_gray =\".15\"\n",
    "sns.set(context=\"notebook\", style=\"ticks\", font_scale=1, #font=\"Bitstream Vera Sans\",\n",
    "        rc={\"axes.edgecolor\": light_gray, \"xtick.color\": dark_gray,\n",
    "            \"ytick.color\": dark_gray, \"xtick.bottom\": True,\n",
    "            \"font.size\":8,\"axes.titlesize\":6,\"axes.labelsize\":6, \"xtick.labelsize\":6, \"legend.fontsize\":6, \n",
    "            \"ytick.labelsize\":6, \"axes.linewidth\":1, \n",
    "            \"xtick.minor.width\":0.5, \"xtick.major.width\":0.5,\n",
    "            \"ytick.minor.width\":0.5, \"ytick.major.width\":0.5, \"lines.linewidth\": 0.7,\n",
    "            \"xtick.major.size\": 3,\n",
    "            \"ytick.major.size\": 3,\n",
    "            \"xtick.minor.size\": 2,\n",
    "            \"ytick.minor.size\": 2,\n",
    "           })\n",
    "width, height, aspect = get_figsize(textwidth, wf=1/5)\n",
    "\n",
    "\n",
    "#g = sns.catplot(data=df.loc[(df.dataset == \"Cora\") | (df.dataset == \"Protein\")].sort_values(by=[\"dataset\", \"Algorithm\"]),\n",
    "#                x=\"Algorithm\", y=\"mean_abs_dev_deg\", errwidth=0, palette=\"tab10\",\n",
    "#                hue=\"neighbor_type\", kind=\"bar\", col=\"dataset\", estimator=np.mean, legend=False, height=width)\n",
    "g = sns.catplot(data=df.loc[(df.dataset == \"BlogCatalog\") | (df.dataset == \"Cora\") | (df.dataset == \"Facebook\") | (df.dataset == \"Protein\") | (df.dataset == \"Wikipedia\")].sort_values(by=[\"dataset\", \"Algorithm\"]),\n",
    "                x=\"Algorithm\", y=\"mean_abs_dev_deg\", errwidth=0, palette=\"tab10\",\n",
    "                hue=\"neighbor_type\", kind=\"bar\", col=\"dataset\", estimator=np.mean, legend=False, height=width, aspect=1)\n",
    "g.set_ylabels(\"Average Mean Absolute Deviation\\nof Angle in Degrees\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.axes[0,3].legend(loc='upper center', bbox_to_anchor=(-0.8, -0.6), fancybox=False, shadow=False, ncol=5)\n",
    "g.set_xlabels(\"\")\n",
    "#g.set_xticklabels([\"HOPE\", \"LINE\", \"node2vec\", \"SDNE\", \"GraphSAGE\"])\n",
    "g.set_xticklabels([\"LINE\", \"node2vec\", \"SDNE\", \"GraphSAGE\"])\n",
    "for i in range(g.axes.shape[1]):\n",
    "    g.axes[0,i].set_xticklabels(g.axes[0,i].get_xticklabels(), rotation=angle, horizontalalignment='right')\n",
    "    \n",
    "for ax in g.axes[0, :]:\n",
    "    ax.set_yticks(np.arange(0, 9, 2))\n",
    "g.savefig(\"plots/nb_var_mad_all.pdf\", bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
